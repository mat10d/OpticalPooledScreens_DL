{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def prepare_data_for_vae_eval(selected_genes_nt_subsample_path, selected_genes_path):\n",
    "    # Read in the data\n",
    "    selected_genes_nt_subsample = pd.read_csv(selected_genes_nt_subsample_path)\n",
    "    selected_genes = pd.read_csv(selected_genes_path)\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    selected_genes_all = pd.concat([selected_genes_nt_subsample, selected_genes])\n",
    "\n",
    "    # Get index of nucleus_dapi_int\n",
    "    nucleus_dapi_int_index = selected_genes_all.columns.get_loc('nucleus_dapi_int')\n",
    "\n",
    "    # Get feature columns\n",
    "    feature_columns = selected_genes_all.columns[nucleus_dapi_int_index:]\n",
    "\n",
    "    # Create a list of columns to keep\n",
    "    columns_to_keep = ['gene_symbol_0'] + list(feature_columns)\n",
    "\n",
    "    # Keep only the selected columns\n",
    "    selected_genes_all_cleaned = selected_genes_all[columns_to_keep]\n",
    "\n",
    "    # Reset index \n",
    "    selected_genes_all_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Split the data into metadata (gene_symbol_0) and features\n",
    "    metadata = selected_genes_all_cleaned['gene_symbol_0']\n",
    "    cp_df = selected_genes_all_cleaned.drop('gene_symbol_0', axis=1)\n",
    "\n",
    "    # Replace Inf with NaN\n",
    "    cp_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Impute missing values with the mean of the column\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    cp_df = imputer.fit_transform(cp_df)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    cp_df_scaled = scaler.fit_transform(cp_df)\n",
    "\n",
    "    # Split into training, validation, and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(cp_df_scaled, metadata, test_size=0.7, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create DataFrames for each split\n",
    "    train_df = pd.DataFrame(X_train, columns=feature_columns)\n",
    "    train_df['gene_symbol_0'] = y_train.values\n",
    "    \n",
    "    val_df = pd.DataFrame(X_val, columns=feature_columns)\n",
    "    val_df['gene_symbol_0'] = y_val.values\n",
    "    \n",
    "    test_df = pd.DataFrame(X_test, columns=feature_columns)\n",
    "    test_df['gene_symbol_0'] = y_test.values\n",
    "\n",
    "    # Create a dictionary to mimic the structure expected by VAE evaluation\n",
    "    results = {\n",
    "        'train': {\n",
    "            'latent_df': train_df.drop('gene_symbol_0', axis=1),\n",
    "            'metadata': pd.DataFrame({'gene': train_df['gene_symbol_0']})\n",
    "        },\n",
    "        'val': {\n",
    "            'latent_df': val_df.drop('gene_symbol_0', axis=1),\n",
    "            'metadata': pd.DataFrame({'gene': val_df['gene_symbol_0']})\n",
    "        },\n",
    "        'test': {\n",
    "            'latent_df': test_df.drop('gene_symbol_0', axis=1),\n",
    "            'metadata': pd.DataFrame({'gene': test_df['gene_symbol_0']})\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def plot_clustermap(data, metadata, output_path):\n",
    "    # Check for infinite or NaN values\n",
    "    if np.any(np.isinf(data)) or np.any(np.isnan(data)):\n",
    "        raise ValueError(\"Data contains infinite or NaN values\")\n",
    "\n",
    "    # Get unique gene symbols and assign colors\n",
    "    gene_symbols = metadata['gene'].unique()\n",
    "    n_colors = len(gene_symbols)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, n_colors))\n",
    "    color_map = dict(zip(gene_symbols, colors))\n",
    "    \n",
    "    # Create a color list for each row\n",
    "    row_colors = metadata['gene'].map(color_map).tolist()\n",
    "    \n",
    "    # Create a clustermap with adjusted parameters\n",
    "    g = sns.clustermap(\n",
    "        data,\n",
    "        row_cluster=True,\n",
    "        col_cluster=True,\n",
    "        cmap='viridis',\n",
    "        figsize=(20, 20),\n",
    "        cbar_kws={'label': 'Standardized Value'},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "        row_colors=row_colors\n",
    "    )\n",
    "    \n",
    "    # Adjust colorbar limits to show more variation\n",
    "    vmin, vmax = np.percentile(data.values, [5, 95])\n",
    "    g.ax_heatmap.collections[0].set_clim(vmin, vmax)\n",
    "    \n",
    "    # Add title\n",
    "    plt.suptitle(\"Feature Clustermap\", fontsize=16, y=1.02)\n",
    "    \n",
    "    # Create a custom legend for gene symbols\n",
    "    legend_elements = [plt.Rectangle((0, 0), 1, 1, fc=color_map[gene], label=gene) for gene in gene_symbols]\n",
    "    plt.legend(handles=legend_elements, title='Gene Symbols', \n",
    "               loc='center left', bbox_to_anchor=(2, 0.5), ncol=1)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "def train_classifier(train_latents, train_labels):\n",
    "    class_names = np.unique(train_labels)\n",
    "    classifier = LogisticRegression(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "    classifier.fit(train_latents, train_labels)\n",
    "    print(f\"Convergence status: {'Converged' if classifier.n_iter_ < classifier.max_iter else 'Did not converge'}\")\n",
    "    print(f\"Number of iterations: {classifier.n_iter_}\")\n",
    "    return classifier, class_names\n",
    "\n",
    "def evaluate_classifier(classifier, latents, labels, class_names):\n",
    "    y_pred = classifier.predict(latents)\n",
    "    y_prob = classifier.predict_proba(latents)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, y_pred)\n",
    "    loss = log_loss(labels, y_prob)\n",
    "    \n",
    "    class_report = classification_report(labels, y_pred, target_names=class_names)\n",
    "    conf_matrix = confusion_matrix(labels, y_pred)\n",
    "    \n",
    "    # Calculate AUC for each class\n",
    "    auc_scores = {}\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        auc_scores[class_name] = roc_auc_score((np.array(labels) == class_name).astype(int), \n",
    "                                               [prob[i] for prob in y_prob])\n",
    "    \n",
    "    # Calculate macro-average AUC\n",
    "    macro_avg_auc = np.mean(list(auc_scores.values()))\n",
    "    \n",
    "    return {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred,\n",
    "        'true_labels': labels,\n",
    "        'probabilities': y_prob,\n",
    "        'classification_report': class_report,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'auc_scores': auc_scores,\n",
    "        'macro_avg_auc': macro_avg_auc\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names, output_path):\n",
    "    conf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(conf_matrix_percent, annot=True, fmt='.1f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix (%)')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    cbar = plt.gca().collections[0].colorbar\n",
    "    cbar.set_label('Percentage (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_curve(true_labels, probabilities, class_names, output_path):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        fpr[i], tpr[i], _ = roc_curve((np.array(true_labels) == class_name).astype(int), \n",
    "                                    [prob[i] for prob in probabilities])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'{class_name} (AUC = {roc_auc[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def save_results(results, output_path, class_names):\n",
    "    summary = pd.DataFrame({\n",
    "        'loss': [results['loss']],\n",
    "        'accuracy': [results['accuracy']],\n",
    "        **{f'auc_{class_name}': [results['auc_scores'][class_name]] for class_name in class_names},\n",
    "        'macro_avg_auc': [results['macro_avg_auc']]\n",
    "    })\n",
    "    summary.to_csv(output_path, index=False)\n",
    "\n",
    "    with open(output_path.replace('.csv', '_report.txt'), 'w') as f:\n",
    "        f.write(results['classification_report'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lab/barcheese01/miniconda3/envs/ops_dl/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/lab/barcheese01/miniconda3/envs/ops_dl/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustermap saved to cct2_nontargeting_diane/train_heatmap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lab/barcheese01/miniconda3/envs/ops_dl/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/lab/barcheese01/miniconda3/envs/ops_dl/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustermap saved to cct2_nontargeting_diane/val_heatmap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lab/barcheese01/miniconda3/envs/ops_dl/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n",
      "/lab/barcheese01/miniconda3/envs/ops_dl/lib/python3.10/site-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustermap saved to cct2_nontargeting_diane/test_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "# make a directory called cct2_nontargeting_diane\n",
    "\n",
    "output_path = 'cct2_nontargeting_diane'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "results = prepare_data_for_vae_eval('cct2.csv', 'nontargeting_subsample_diane.csv')\n",
    "classifier, class_names = train_classifier(results['train']['latent_df'], results['train']['metadata']['gene'])\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    plot_clustermap(results[split]['latent_df'], results[split]['metadata'], f'{output_path}/{split}_heatmap.png')\n",
    "    split_results = evaluate_classifier(classifier, results[split]['latent_df'], results[split]['metadata']['gene'], class_names)\n",
    "    plot_confusion_matrix(split_results['confusion_matrix'], class_names, f'{output_path}/{split}_confusion_matrix.png')\n",
    "    plot_roc_curve(split_results['true_labels'], split_results['probabilities'], class_names, f'{output_path}/{split}_roc_curve.png')\n",
    "    save_results(split_results, f'{output_path}/{split}_results.csv', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
